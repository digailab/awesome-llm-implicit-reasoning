<div align="center">
    <h1><b>A Survey on LLM Implicit Reasoning</b></h1>
</div>

The official GitHub page for the survey paper "A Survey on LLM Implicit Reasoning".


<div align="center">

![](https://img.shields.io/github/stars/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=yellow&cacheSeconds=60)
![](https://img.shields.io/github/forks/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=lightblue)
![](https://img.shields.io/github/last-commit/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=green)
![](https://img.shields.io/badge/PRs-Welcome-blue)
<a href="https://arxiv.org/" target="_blank"><img src="https://img.shields.io/badge/arXiv-xxxx.xxxxx-009688.svg" alt="arXiv"></a>

</div>


## Related Survey

1. 2025_arXiv_Survey_A Survey of Efficient Reasoning for Large Reasoning Models= Language, Multimodality, and Beyond. [[arXiv]](https://arxiv.org/abs/2503.21614) [[Github]](https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning)
 
2. 2025_arXiv_Survey_Efficient Inference for Large Reasoning Models= A Survey. [[arXiv]](https://arxiv.org/abs/2503.23077) [[Github]](https://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs)
 
3. 2025_arXiv_Survey_Efficient Reasoning Models= A Survey. [[arXiv]](https://arxiv.org/abs/2504.10903) [[Github]](https://github.com/fscdc/Awesome-Efficient-Reasoning-Models)
 
4. 2025_arXiv_Survey_Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models. [[arXiv]](https://arxiv.org/abs/2503.24377) [[Github]](https://github.com/DevoAllen/Awesome-Reasoning-Economy-Papers)
 
5. 2025_arXiv_Survey_Stop Overthinking=A Survey on Efficient Reasoning for Large Language Models. [[arXiv]](https://arxiv.org/abs/2503.16419) [[Github]](https://github.com/Eclipsess/Awesome-Efficient-Reasoning-LLMs)
 
6. 2025_Survey_Reasoning Beyond Language= A Comprehensive Survey on Latent Chain-of-Thought Reasoning. [[arXiv]](https://arxiv.org/abs/2505.16782) [[Github]](https://github.com/EIT-NLP/Awesome-Latent-CoT)


## Related Reposority

1. hemingkx / Awesome-Efficient-Reasoning. [[Github]](https://github.com/hemingkx/Awesome-Efficient-Reasoning)
2. Blueyee / Efficient-CoT-LRMs. [[Github]](https://github.com/Blueyee/Efficient-CoT-LRMs)
3. Hongcheng-Gao / Awesome-Long2short-on-LRMs. [[Github]](https://github.com/Hongcheng-Gao/Awesome-Long2short-on-LRMs)
4. zcccccz / Awesome-LLM-Implicit-Reasoning. [[Github]](https://github.com/zcccccz/Awesome-LLM-Implicit-Reasoning)



## 3. Methodological Landscape of Implicit Reasoning

### 3.1 Latent-State Reasoning Representations
#### 3.1.1 Discrete or Continuous Latent CoT Tokens

1. 2025_arXiv_LPC_Latent Preference Coding=Aligning Large Language Models via Discrete Latent Codes.
   
2. 2025_arXiv_Token Assorted_Token Assorted= Mixing Latent and Text Tokens for Improved Language Model Reasoning.

3. 2025_arXiv_LTMs_Scalable Language Models with Posterior Inference of Latent Thought Vectors.
[[arXiv]](https://arxiv.org/abs/2502.01567)

4. 2025_arXiv_CoCoMix_LLM Pretraining with Continuous Concepts.
 
5. 2025_arXiv_Enhancing Latent Computation in Transformers with Latent Tokens.



#### 3.1.2 Compressed or Structured Reasoning Trajectories

1. 2024_arXiv_CCoT_Compressed Chain of Thought= Efficient Reasoning through Dense Representations.
[[arXiv]](https://arxiv.org/abs/2412.13171)

2. 2024_arXiv_Coconut_Training Large Language Models to Reason in a Continuous Latent Space.
[[arXiv]](https://arxiv.org/abs/2412.06769)

3. 2024_arXiv_HCoT+Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding.

4. 2025_ACL_SoftCoT_SoftCoT=Soft Chain-of-Thought for Efficient Reasoning with LLMs.
[[arXiv]](https://arxiv.org/abs/2502.12134)
[[Code-Github]](https://github.com/xuyige/SoftCoT)
[[Data-Huggingface]](https://huggingface.co/datasets/xuyige/ASDiv-Aug)

5. 2025_arXiv_SoftCoT++_SoftCoT++=Test-Time Scaling with Soft Chain-of-Thought Reasoning.

6. 2025_arXiv_LightThinker_LightThinker=Thinking Step-by-Step Compression.
[[arXiv]](https://arxiv.org/abs/2502.15589)
[[Code--Github]](https://github.com/zjunlp/LightThinker)

7. 2025_arXiv_CoT-Valve_CoT-Valve=Length-Compressible Chain-of-Thought Tuning.
[[arXiv]](https://arxiv.org/abs/2502.09601)
[[Code--Github]](https://github.com/horseee/CoT-Valve)

8. 2025_arXiv_CODI_CODI=Compressing Chain-of-Thought into Continuous Space via Self-Distillation.
[[arXiv]](https://arxiv.org/abs/2502.21074)

9. 2025_arXiv_Heima_Efficient Reasoning with Hidden Thinking.
[[arXiv]](https://arxiv.org/abs/2501.19201)
[[Code--Github]](https://github.com/shawnricecake/Heima)

10. 2025_arXiv_Soft Thinking_Soft Thinking= Unlocking the Reasoning Potential of LLMs in Continuous Concept Space.

11. 2025_arXiv_PonderingLM_Pretraining Language Models to Ponder in Continuous Space.



#### 3.1.3 Diffusion-Driven or Memory-Augmented Reasoning

1. 2024_NeruIPS_DoT_Diffusion of Thought= Chain-of-Thought Reasoning in Diffusion Language Models.
 
2. 2025_arXiv_CoT2_Continuous Chain of Thought Enables Parallel Exploration and Reasoning.
 
3. 2025_arXiv_DCoLT_Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models.
 
4. 2025_arXiv_Beyond Words_Beyond Words=A Latent Memory Approach to Internal Reasoning in LLMs.
[[arXiv]](https://arxiv.org/abs/2502.21030)

5. 2025_arXiv_BoLT_Reasoning to Learn from Latent Thoughts.
 
6. 2025_arXiv_ReaRec_Think Before Recommend= Unleashing the Latent Reasoning Power for Sequential Recommendation.





