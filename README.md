<div align="center">
    <h1><b>A Survey on LLM Implicit Reasoning</b></h1>
</div>

The official GitHub page for the survey paper "A Survey on LLM Implicit Reasoning".


<div align="center">

![](https://img.shields.io/github/stars/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=yellow)
![](https://img.shields.io/github/forks/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=lightblue)
![](https://img.shields.io/github/last-commit/jindongli-Ai/LLM-Implicit-Reasoning-Survey?color=green)
![](https://img.shields.io/badge/PRs-Welcome-blue)
<a href="https://arxiv.org/" target="_blank"><img src="https://img.shields.io/badge/arXiv-xxxx.xxxxx-009688.svg" alt="arXiv"></a>

</div>





## (1) Latent Reasoning Space Construction

1. 2024_arXiv_CCoT_Compressed Chain of Thought: Efficient Reasoning through Dense Representations.

   [[arXiv]](https://arxiv.org/abs/2412.13171)
   
2. 2024_arXiv_Coconut_Training Large Language Models to Reason in a Continuous Latent Space.

   [[arXiv]](https://arxiv.org/abs/2412.06769)
   
3. 2024_arXiv_From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step.

   [[arXiv]](https://arxiv.org/abs/2405.14838)
   
4. 2025_arXiv_CODI_CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation.

   [[arXiv]](https://arxiv.org/abs/2502.21074)
   
5. 2025_arXiv_LightThinker_LightThinker: Thinking Step-by-Step Compression.

   [[arXiv]](https://arxiv.org/abs/2502.15589)&nbsp;
   [[Code--Github]](https://github.com/zjunlp/LightThinker)
    
6. 2025_arXiv_LTMs_Scalable Language Models with Posterior Inference of Latent Thought Vectors.

   [[arXiv]](https://arxiv.org/abs/2502.01567)

7. 2025_ACL_SoftCoT_SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs.
    
   [[arXiv]](https://arxiv.org/abs/2502.12134) &nbsp;
   [[Code--Github]](https://github.com/xuyige/SoftCoT)&nbsp;
   [[Data--Huggingface]](https://huggingface.co/datasets/xuyige/ASDiv-Aug)

8. 2025_arXiv_SoftCoT++_SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning

   [[arXiv]](https://arxiv.org/abs/2505.11484)&nbsp;
   [[Code--Github]](https://github.com/xuyige/SoftCoT)



## (2) Hidden State-Based Inference

1. 2023_arXiv_ImplicitCoT_Implicit Chain of Thought Reasoning via Knowledge Distillation.

   [[arXiv]](https://arxiv.org/abs/2311.01460)&nbsp;
   [[Code, Data, Pretrained Model--Github]](https://github.com/da03/implicit_chain_of_thought/)
   
2. 2025_arXiv_CoT-Valve_CoT-Valve: Length-Compressible Chain-of-Thought Tuning.

   [[arXiv]](https://arxiv.org/abs/2502.09601)&nbsp;
   [[Code--Github]](https://github.com/horseee/CoT-Valve)
   
3. 2025_arXiv_Heima_Efficient Reasoning with Hidden Thinking.

   [[arXiv]](https://arxiv.org/abs/2501.19201)&nbsp;
   [[Code--Github]](https://github.com/shawnricecake/Heima)
 



## (3) Recurrent or Progressive Depth

1. 2025_arXiv_Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach.
   
   [[arXiv]](https://arxiv.org/abs/2502.05171)&nbsp;
   [[Model--Huggingface]](https://huggingface.co/tomg-group-umd/huginn-0125)&nbsp;
   [[Code and Data--Github]](https://github.com/seal-rg/recurrent-pretraining)
   
2. 2025_ICLR_Reasoning with Latent Thoughts: On the Power of Looped Transformers.
   
   [[arXiv]](https://arxiv.org/abs/2502.17416)&nbsp;
   [[ICLR]](https://iclr.cc/virtual/2025/poster/28971)&nbsp;
   [[Poster]](https://iclr.cc/media/iclr-2025/Slides/28971.pdf)&nbsp;
   [[Youtube]](https://www.youtube.com/watch?v=S22Bs07HD0k)



## (4) Compositional & Memory-Augmented

1. 2025_arXiv_Beyond Words_Beyond Words: A Latent Memory Approach to Internal Reasoning in LLMs.

   [[arXiv]](https://arxiv.org/abs/2502.21030)


